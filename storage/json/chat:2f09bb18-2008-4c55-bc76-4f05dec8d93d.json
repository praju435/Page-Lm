[
  {
    "pageContent": "Project Title:\n\nSign Language to Text\n\n\n\n\n\n\n\n\n\n\n\nTEAM NO.: 106\n\nNAMES OF THE STUDENTS PARTICIPATED IN THE TEAM:\n\nSANCHIT AGARKAR, PRANAV UNKULE, PRATIK SAURKAR, CHATAK SHINDE\n\n\n\nCOLLEGE: MIT ACADEMY OF ENGINEERING, ALANDI, PUNE SEMESTER: 7\n\nDEPARTMENT: ELEECTRONICS AND TELECOMMUNICATION CITY: PUNE\n\nSTATE: MAHARASHTRA\n\nPROJECT MENTOR NAME: MS. MALA MISHRA\n\n\n\n\t\t\n\n\n\nProject Details:",
    "metadata": {
      "loc": {
        "lines": {
          "from": 19,
          "to": 55
        }
      }
    }
  },
  {
    "pageContent": "Project Details:\n\nAn interface that bridge the communication barrier by converting sign language gesture to written text and display the same also convert the displayed text into audio.\n\nProblem Statement:\n\nTo develop a system to convert Indian sign language into text to help hearing impaired /deaf people while communicating with the rest of the world.\n\nNeed of Project:",
    "metadata": {
      "loc": {
        "lines": {
          "from": 55,
          "to": 63
        }
      }
    }
  },
  {
    "pageContent": "Sign language is a channel of conversation used by people with impaired hearing and speech. In contrast, non-signers find it utterly difficult to understand and respond to the actions, and gestures of hearing and speech-impaired people, hence qualified sign language interpreters are needed during legal and medical appointments. But, India has a total of 250 certified interpreters and so there was a need for a system that will incorporate conversation of sign language to remove this communication barrier.",
    "metadata": {
      "loc": {
        "lines": {
          "from": 65,
          "to": 65
        }
      }
    }
  },
  {
    "pageContent": "There are around 300 sign languages used worldwide which include American Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language (ISL), etc. Many kinds of research and project works are done on sign language. It is observed that most of the work is done in American Sign Language (ASL). But there is no such advancement in other sign languages. In India, deaf and dumb people use Indian Sign Language (ISL) to communicate. According to the World Health Organization, over 5% of the world",
    "metadata": {
      "loc": {
        "lines": {
          "from": 67,
          "to": 67
        }
      }
    }
  },
  {
    "pageContent": "over 5% of the world population suffers from disabling hearing loss out of which 34 million are teenagers. One improvement that arrived was a requirement for educational facilities such as specialized schools for deaf and dumb people.",
    "metadata": {
      "loc": {
        "lines": {
          "from": 67,
          "to": 67
        }
      }
    }
  },
  {
    "pageContent": "After these observations and statistics, it is proposed to give a platform for deaf and dumb people to express their thoughts, emotions, feelings, creativity, and explore the world. Also, by converting detected text to audio format it is assured to make communication more comfortable for such special people.\n\n\n\nProposed Solution:",
    "metadata": {
      "loc": {
        "lines": {
          "from": 69,
          "to": 73
        }
      }
    }
  },
  {
    "pageContent": "Proposed Solution:\n\nThe proposed model consists of Convolution Neural Network based Alexnet Architecture which predict the gesture into text and furthermore the predicted text is converted to audio using a python library named pyttsx3.\n\nTechnology Used:\n\nComputer Vision (Dataset Creation and Image Feed)\n\nCanny Edge Filtering (Dataset Pre-processing)\n\nTensorFlow (Implementation of Deep Learning Model)\n\nTkinter (GUI Creation)\n\nPyttsx3 (Audio Conversion)\n\nProject Outcomes:",
    "metadata": {
      "loc": {
        "lines": {
          "from": 73,
          "to": 89
        }
      }
    }
  },
  {
    "pageContent": "Project Outcomes:\n\nThe system classifies the shown gesture into text on the screen and along with it gives the audio output for the corresponding gesture.\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\t\t\n\n\n\nModelling:\n\nThe project consists of main 3 steps:\n\nDataset Creation:\n\nTo create datasets and perform pre-processing operations on them, “OpenCV” is used. The dataset consists of pre-processed images taken from video frames which were captured using a laptop camera. For pre-processing, the Canny Edge Filtering technique is used.",
    "metadata": {
      "loc": {
        "lines": {
          "from": 89,
          "to": 119
        }
      }
    }
  },
  {
    "pageContent": "Training the model over dataset:ss\n\nThe created dataset is then feed to CNN model for training and the weights are saved into the Jason format which are then used for prediction purpose.\n\n\n\nReal-Time Prediction and Audio Conversion:",
    "metadata": {
      "loc": {
        "lines": {
          "from": 123,
          "to": 129
        }
      }
    }
  },
  {
    "pageContent": "In real-time prediction the image feed from the camera is pre-processed and the pre- processed image is passed down to the saved model from classification purpose and the text is displayed over the screen, also the text is converted into audio with the help of “pyttsx3” library.\n\nThe steps can we visualized by seeing the below block diagram\n\n\n\nResults:\n\nGraphical User Interface (GUI):\n\n\n\n\n\n\n\n\n\n2\n\n\n\n\t\t\n\n\n\n\n\n\n\nReal-Time Prediction Output:\n\n\n\n\n\nFuture scope for project enhancement:",
    "metadata": {
      "loc": {
        "lines": {
          "from": 131,
          "to": 167
        }
      }
    }
  },
  {
    "pageContent": "The proposed system was trained on static gesture images and it can be extended for the prediction of dynamic gestures. Currently, the model is trained on 22 gestures but ISL is vast and contains thousands of gestures so this model can be extended to classify more gestures. Also, this model can only be used in certain situations due to limitations of background, so further research and work are required to remove these limitations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3",
    "metadata": {
      "loc": {
        "lines": {
          "from": 169,
          "to": 221
        }
      }
    }
  }
]